{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import logging\n",
    "from Modules.Loader_wrangler import *\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure basic logging\n",
    "logging.basicConfig(level=logging.INFO, force=True, format='%(levelname)s: %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m play \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmerged_df2017.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msurvey_year\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2017\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Cambridge24.25/D200_ML_econ/ProblemSets/Project/Modules/Loader_wrangler.py:306\u001b[0m, in \u001b[0;36mloader\u001b[0;34m(output_file_name, wrangle_func, nts_trip, nts_vehicle, nts_i, nts_household, nts_psu, nts_day, chunksize, sample_size, survey_year)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;124;03mLoads, merges, and processes National Travel Survey (NTS) datasets in chunks.\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;124;03m    A fully merged and processed DataFrame containing travel data.\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# Load in vehicle df\u001b[39;00m\n\u001b[0;32m--> 306\u001b[0m vehicle_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnts_vehicle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;66;03m# Load in Individual df\u001b[39;00m\n\u001b[1;32m    310\u001b[0m i_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(nts_i, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,  dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/MLEconPS2/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/MLEconPS2/lib/python3.12/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/MLEconPS2/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/MLEconPS2/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<frozen codecs>:331\u001b[0m, in \u001b[0;36mgetstate\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "play = loader(output_file_name=\"merged_df2017.pkl\", chunksize=100000, sample_size=100000, survey_year=2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "play = pd.read_pickle(\"/home/trapfishscott/Cambridge24.25/D200_ML_econ/ProblemSets/Project/data/merged_df2017.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining only relevant variables and making into a time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_vars = [\"TWSMonth\", \"TravelYear\", \"TravelWeekDay_B01ID\"]\n",
    "individual_vars =[\"PSUGOR_B02ID\", \"IndIncome2002_B02ID\", \"HHoldNumChildren\", \"VehMakeModel_B02ID\"]\n",
    "\n",
    "outcome_vars = [\"TripStart\", \"TripEnd\", \"TripDisExSW\", \"TripPurpose_B01ID\"]\n",
    "extra_vars = [\"IndividualID_x\", \"JourSeq\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df = play[extra_vars + individual_vars + temporal_vars + outcome_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df = ts_df.sort_values([\"IndividualID_x\", \"TravelWeekDay_B01ID\", \"JourSeq\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IndividualID_x</th>\n",
       "      <th>JourSeq</th>\n",
       "      <th>PSUGOR_B02ID</th>\n",
       "      <th>IndIncome2002_B02ID</th>\n",
       "      <th>HHoldNumChildren</th>\n",
       "      <th>VehMakeModel_B02ID</th>\n",
       "      <th>TWSMonth</th>\n",
       "      <th>TravelYear</th>\n",
       "      <th>TravelWeekDay_B01ID</th>\n",
       "      <th>TripStart</th>\n",
       "      <th>TripEnd</th>\n",
       "      <th>TripDisExSW</th>\n",
       "      <th>TripPurpose_B01ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15434</th>\n",
       "      <td>2.017000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16026</th>\n",
       "      <td>2.017000e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>690.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15433</th>\n",
       "      <td>2.017000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12891</th>\n",
       "      <td>2.017000e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>995.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16027</th>\n",
       "      <td>2.017000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19029</th>\n",
       "      <td>2.017017e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25809</th>\n",
       "      <td>2.017017e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37414</th>\n",
       "      <td>2.017017e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>645.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43207</th>\n",
       "      <td>2.017017e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32708</th>\n",
       "      <td>2.017017e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>860.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98540 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       IndividualID_x  JourSeq  PSUGOR_B02ID  IndIncome2002_B02ID  \\\n",
       "15434    2.017000e+09      1.0           5.0                  1.0   \n",
       "16026    2.017000e+09      2.0           5.0                  1.0   \n",
       "15433    2.017000e+09      1.0           5.0                  1.0   \n",
       "12891    2.017000e+09      2.0           5.0                  1.0   \n",
       "16027    2.017000e+09      1.0           5.0                  1.0   \n",
       "...               ...      ...           ...                  ...   \n",
       "19029    2.017017e+09      1.0           7.0                  1.0   \n",
       "25809    2.017017e+09      1.0           7.0                  1.0   \n",
       "37414    2.017017e+09      2.0           7.0                  1.0   \n",
       "43207    2.017017e+09      1.0           7.0                  1.0   \n",
       "32708    2.017017e+09      2.0           7.0                  1.0   \n",
       "\n",
       "       HHoldNumChildren  VehMakeModel_B02ID  TWSMonth  TravelYear  \\\n",
       "15434               0.0               -10.0       1.0      2017.0   \n",
       "16026               0.0               -10.0       1.0      2017.0   \n",
       "15433               0.0               -10.0       1.0      2017.0   \n",
       "12891               0.0               -10.0       1.0      2017.0   \n",
       "16027               0.0               -10.0       1.0      2017.0   \n",
       "...                 ...                 ...       ...         ...   \n",
       "19029               0.0               -10.0       1.0      2018.0   \n",
       "25809               0.0               -10.0       1.0      2018.0   \n",
       "37414               0.0               -10.0       1.0      2018.0   \n",
       "43207               0.0               -10.0       1.0      2018.0   \n",
       "32708               0.0               -10.0       1.0      2018.0   \n",
       "\n",
       "       TravelWeekDay_B01ID  TripStart  TripEnd  TripDisExSW  TripPurpose_B01ID  \n",
       "15434                  1.0      600.0    620.0          4.0                6.0  \n",
       "16026                  1.0      690.0    710.0          4.0                6.0  \n",
       "15433                  5.0      540.0    580.0          6.0               13.0  \n",
       "12891                  5.0      960.0    995.0          6.0               13.0  \n",
       "16027                  1.0      480.0    560.0         22.0                1.0  \n",
       "...                    ...        ...      ...          ...                ...  \n",
       "19029                  4.0      570.0    840.0        100.0               15.0  \n",
       "25809                  5.0      570.0    585.0          2.0                5.0  \n",
       "37414                  5.0      645.0    660.0          2.0                5.0  \n",
       "43207                  6.0      660.0    680.0          2.0               13.0  \n",
       "32708                  6.0      840.0    860.0          2.0               13.0  \n",
       "\n",
       "[98540 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most weekly travel ~ 67\n",
      "Average weekly travel ~ 14.4106463878327\n",
      "97th percentile of weekly travel ~ 34.0\n"
     ]
    }
   ],
   "source": [
    "weekly_travel = []\n",
    "\n",
    "\n",
    "for i in ts_df[\"IndividualID_x\"].unique():\n",
    "    i_df = ts_df[ts_df[\"IndividualID_x\"] == i]\n",
    "    weekly_travel.append(len(i_df))\n",
    "\n",
    "max_weekly_travel = max(weekly_travel)\n",
    "mean_weekly_travel = sum(weekly_travel)/ len(weekly_travel)\n",
    "\n",
    "print(f\"Most weekly travel ~ {max_weekly_travel}\")\n",
    "print(f\"Average weekly travel ~ {mean_weekly_travel}\")\n",
    "\n",
    "\n",
    "percentile_97 = np.percentile(weekly_travel, 97)\n",
    "\n",
    "print(f\"97th percentile of weekly travel ~ {percentile_97}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Manipulation pipeline\n",
    "\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_travel_week_for_i(i_df, i_id, full_week_encoding):\n",
    "        \n",
    "    break_flag = False\n",
    "\n",
    "    # Travel days with travel \n",
    "    included_travel_day = i_df[\"TravelWeekDay_B01ID\"].to_list()\n",
    "\n",
    "    # Travel days with no travel\n",
    "    travel_day_no_drive = list(set(full_week_encoding) - set(included_travel_day))\n",
    "\n",
    "    # These values will repeat for empty-travel travel days\n",
    "    imputed_travel_df = pd.DataFrame({\n",
    "        \"TravelWeekDay_B01ID\": travel_day_no_drive,\n",
    "        \"IndividualID_x\": [i_id]*len(travel_day_no_drive),\n",
    "        \"JourSeq\": [1]*len(travel_day_no_drive)\n",
    "    })\n",
    "\n",
    "    # Looping through all the columns in the original df\n",
    "    for col in i_df.columns:\n",
    "\n",
    "        # For days with no travel all outcomes vars will take 0\n",
    "        if col in outcome_vars:\n",
    "            imputed_travel_df[col] = [0]*len(travel_day_no_drive)\n",
    "        \n",
    "        # Individual vars will repeat\n",
    "        if col in individual_vars:\n",
    "\n",
    "            # Repeating individual vars (or temporal vars) usually signify an error\n",
    "            if len(i_df[col].unique()) != 1:\n",
    "                print(f\"{col} is erroneous for {i}\")\n",
    "                print(f\"Unique vals: {i_df[col].unique()}\")\n",
    "                break_flag = True\n",
    "                break\n",
    "            else:\n",
    "                imputed_travel_df[col] = i_df[col].unique()[0]\n",
    "\n",
    "        if col != \"TravelWeekDay_B01ID\" and col in temporal_vars:\n",
    "            if len(i_df[col].unique()) != 1:\n",
    "                print(f\"{col} is erroneous for {i}\")\n",
    "                print(f\"Unique vals: {i_df[col].unique()}\")\n",
    "                break_flag = True\n",
    "                break\n",
    "            else:\n",
    "                imputed_travel_df[col] = i_df[col].unique()[0]\n",
    "\n",
    "    if break_flag:\n",
    "        print(\"Continuing to next individual\")\n",
    "        return\n",
    "    \n",
    "\n",
    "    # display(imputed_travel_df)\n",
    "\n",
    "    # Concatenating df to include empty travel days\n",
    "    full_df = pd.concat([i_df, imputed_travel_df])\n",
    "\n",
    "    full_df = full_df.sort_values([\"TravelYear\", \"TWSMonth\", \"TravelWeekDay_B01ID\", \"JourSeq\", \"TripStart\", \"TripEnd\"])\n",
    "\n",
    "\n",
    "    #display(full_df)\n",
    "\n",
    "\n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_wide_for_i(i_df, max_journey_seq, seq_length = 7, outcome_vars=outcome_vars):\n",
    "    df = i_df.copy()\n",
    "\n",
    "    expected_cols = [f\"{col}_{i}\" for col in outcome_vars for i in range(1, max_journey_seq+1)]\n",
    "\n",
    "    df = df[df[\"JourSeq\"]<=max_journey_seq]\n",
    "\n",
    "    #\n",
    "\n",
    "    df_wide = df.pivot(index=\"TravelWeekDay_B01ID\",\n",
    "                  columns = \"JourSeq\",\n",
    "                  values = outcome_vars)\n",
    "    \n",
    "    df_wide.columns = [f\"{col[0]}_{int(col[1])}\" for col in df_wide.columns]\n",
    "\n",
    "    for col in expected_cols:\n",
    "        if col not in df_wide.columns:\n",
    "            df_wide[col] = 0\n",
    "    \n",
    "    # Ensure column order is consistent\n",
    "    df_wide = df_wide[expected_cols]\n",
    "    \n",
    "    df_wide = df_wide.fillna(0)\n",
    "\n",
    "    df_wide.reset_index(inplace=True)\n",
    "\n",
    "    # Dropping outcome columns\n",
    "    df.drop(columns=outcome_vars + [\"IndividualID_x\",\t\"JourSeq\"], axis=1, inplace = True)\n",
    "    df.drop_duplicates(subset=[\"TravelWeekDay_B01ID\"], inplace=True)\n",
    "\n",
    "    df_wide = df_wide.merge(df, on=\"TravelWeekDay_B01ID\", how=\"left\")\n",
    "\n",
    "    top_row = df_wide.head(1).copy()\n",
    "\n",
    "    for col in expected_cols:\n",
    "        top_row[col] = 0\n",
    "        top_row[\"TravelWeekDay_B01ID\"] = 0\n",
    "\n",
    "    repeated_rows = pd.concat([top_row] * seq_length, ignore_index=True)\n",
    "\n",
    "    df_wide = pd.concat([repeated_rows, df_wide], ignore_index=True)\n",
    "\n",
    "    return df_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_LSTM(long_df, impute_missing_travel_weeks=True, transform_to_wide=False, transform_to_tensor=False, debug=False):\n",
    "\n",
    "    df = long_df.copy()\n",
    "    individual_ids = df[\"IndividualID_x\"].unique()       # All unique individual id's to loop over\n",
    "    df_chunks = []\n",
    "\n",
    "    full_week_encoding = list(range(1,8))\n",
    "\n",
    "    if debug:\n",
    "        random_index = random.randint(0, len(individual_ids))\n",
    "\n",
    "        debug_df = df[df[\"IndividualID_x\"] == individual_ids[random_index]]\n",
    "\n",
    "        display(debug_df)\n",
    "\n",
    "        debug_df = impute_missing_travel_week_for_i(debug_df, i_id=individual_ids[random_index], full_week_encoding=full_week_encoding)\n",
    "\n",
    "        display(debug_df)\n",
    "\n",
    "        debug_df = transform_to_wide_for_i(debug_df, max_journey_seq=10)\n",
    "\n",
    "        display(debug_df)\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    if impute_missing_travel_weeks:\n",
    "\n",
    "\n",
    "\n",
    "        for individual_id in individual_ids[:1]:\n",
    "\n",
    "            i_df = df[df[\"IndividualID_x\"] == individual_id]\n",
    "\n",
    "            full_df = impute_missing_travel_week_for_i(i_df, i_id=individual_id, full_week_encoding=full_week_encoding)\n",
    "\n",
    "            #display(full_df)\n",
    "\n",
    "            if full_df is not None:\n",
    "                if not transform_to_wide:\n",
    "                    df_chunks.append(full_df)\n",
    "\n",
    "                else:\n",
    "                    \n",
    "                    if transform_to_tensor:\n",
    "                        pass\n",
    "\n",
    "                    else:\n",
    "                        full_df = transform_to_wide_for_i(full_df, max_journey_seq=10)\n",
    "                        display(full_df)\n",
    "                        df_chunks.append(full_df)\n",
    "\n",
    "                    \n",
    "\n",
    "        \n",
    "        df_to_return = pd.concat(df_chunks)\n",
    "\n",
    "        return df_to_return\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_data_for_LSTM(long_df=ts_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IndividualID_x</th>\n",
       "      <th>JourSeq</th>\n",
       "      <th>PSUGOR_B02ID</th>\n",
       "      <th>IndIncome2002_B02ID</th>\n",
       "      <th>HHoldNumChildren</th>\n",
       "      <th>VehMakeModel_B02ID</th>\n",
       "      <th>TWSMonth</th>\n",
       "      <th>TravelYear</th>\n",
       "      <th>TravelWeekDay_B01ID</th>\n",
       "      <th>TripStart</th>\n",
       "      <th>TripEnd</th>\n",
       "      <th>TripDisExSW</th>\n",
       "      <th>TripPurpose_B01ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15434</th>\n",
       "      <td>2.017000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16026</th>\n",
       "      <td>2.017000e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>690.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.017000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.017000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.017000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15433</th>\n",
       "      <td>2.017000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12891</th>\n",
       "      <td>2.017000e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>995.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.017000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.017000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       IndividualID_x  JourSeq  PSUGOR_B02ID  IndIncome2002_B02ID  \\\n",
       "15434    2.017000e+09      1.0           5.0                  1.0   \n",
       "16026    2.017000e+09      2.0           5.0                  1.0   \n",
       "0        2.017000e+09      1.0           5.0                  1.0   \n",
       "1        2.017000e+09      1.0           5.0                  1.0   \n",
       "2        2.017000e+09      1.0           5.0                  1.0   \n",
       "15433    2.017000e+09      1.0           5.0                  1.0   \n",
       "12891    2.017000e+09      2.0           5.0                  1.0   \n",
       "3        2.017000e+09      1.0           5.0                  1.0   \n",
       "4        2.017000e+09      1.0           5.0                  1.0   \n",
       "\n",
       "       HHoldNumChildren  VehMakeModel_B02ID  TWSMonth  TravelYear  \\\n",
       "15434               0.0               -10.0       1.0      2017.0   \n",
       "16026               0.0               -10.0       1.0      2017.0   \n",
       "0                   0.0               -10.0       1.0      2017.0   \n",
       "1                   0.0               -10.0       1.0      2017.0   \n",
       "2                   0.0               -10.0       1.0      2017.0   \n",
       "15433               0.0               -10.0       1.0      2017.0   \n",
       "12891               0.0               -10.0       1.0      2017.0   \n",
       "3                   0.0               -10.0       1.0      2017.0   \n",
       "4                   0.0               -10.0       1.0      2017.0   \n",
       "\n",
       "       TravelWeekDay_B01ID  TripStart  TripEnd  TripDisExSW  TripPurpose_B01ID  \n",
       "15434                  1.0      600.0    620.0          4.0                6.0  \n",
       "16026                  1.0      690.0    710.0          4.0                6.0  \n",
       "0                      2.0        0.0      0.0          0.0                0.0  \n",
       "1                      3.0        0.0      0.0          0.0                0.0  \n",
       "2                      4.0        0.0      0.0          0.0                0.0  \n",
       "15433                  5.0      540.0    580.0          6.0               13.0  \n",
       "12891                  5.0      960.0    995.0          6.0               13.0  \n",
       "3                      6.0        0.0      0.0          0.0                0.0  \n",
       "4                      7.0        0.0      0.0          0.0                0.0  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TravelWeekDay_B01ID</th>\n",
       "      <th>TripStart_1</th>\n",
       "      <th>TripStart_2</th>\n",
       "      <th>TripStart_3</th>\n",
       "      <th>TripStart_4</th>\n",
       "      <th>TripStart_5</th>\n",
       "      <th>TripStart_6</th>\n",
       "      <th>TripStart_7</th>\n",
       "      <th>TripStart_8</th>\n",
       "      <th>TripStart_9</th>\n",
       "      <th>...</th>\n",
       "      <th>TripPurpose_B01ID_7</th>\n",
       "      <th>TripPurpose_B01ID_8</th>\n",
       "      <th>TripPurpose_B01ID_9</th>\n",
       "      <th>TripPurpose_B01ID_10</th>\n",
       "      <th>PSUGOR_B02ID</th>\n",
       "      <th>IndIncome2002_B02ID</th>\n",
       "      <th>HHoldNumChildren</th>\n",
       "      <th>VehMakeModel_B02ID</th>\n",
       "      <th>TWSMonth</th>\n",
       "      <th>TravelYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>690.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    TravelWeekDay_B01ID  TripStart_1  TripStart_2  TripStart_3  TripStart_4  \\\n",
       "0                   0.0          0.0          0.0            0            0   \n",
       "1                   0.0          0.0          0.0            0            0   \n",
       "2                   0.0          0.0          0.0            0            0   \n",
       "3                   0.0          0.0          0.0            0            0   \n",
       "4                   0.0          0.0          0.0            0            0   \n",
       "5                   0.0          0.0          0.0            0            0   \n",
       "6                   0.0          0.0          0.0            0            0   \n",
       "7                   1.0        600.0        690.0            0            0   \n",
       "8                   2.0          0.0          0.0            0            0   \n",
       "9                   3.0          0.0          0.0            0            0   \n",
       "10                  4.0          0.0          0.0            0            0   \n",
       "11                  5.0        540.0        960.0            0            0   \n",
       "12                  6.0          0.0          0.0            0            0   \n",
       "13                  7.0          0.0          0.0            0            0   \n",
       "\n",
       "    TripStart_5  TripStart_6  TripStart_7  TripStart_8  TripStart_9  ...  \\\n",
       "0             0            0            0            0            0  ...   \n",
       "1             0            0            0            0            0  ...   \n",
       "2             0            0            0            0            0  ...   \n",
       "3             0            0            0            0            0  ...   \n",
       "4             0            0            0            0            0  ...   \n",
       "5             0            0            0            0            0  ...   \n",
       "6             0            0            0            0            0  ...   \n",
       "7             0            0            0            0            0  ...   \n",
       "8             0            0            0            0            0  ...   \n",
       "9             0            0            0            0            0  ...   \n",
       "10            0            0            0            0            0  ...   \n",
       "11            0            0            0            0            0  ...   \n",
       "12            0            0            0            0            0  ...   \n",
       "13            0            0            0            0            0  ...   \n",
       "\n",
       "    TripPurpose_B01ID_7  TripPurpose_B01ID_8  TripPurpose_B01ID_9  \\\n",
       "0                     0                    0                    0   \n",
       "1                     0                    0                    0   \n",
       "2                     0                    0                    0   \n",
       "3                     0                    0                    0   \n",
       "4                     0                    0                    0   \n",
       "5                     0                    0                    0   \n",
       "6                     0                    0                    0   \n",
       "7                     0                    0                    0   \n",
       "8                     0                    0                    0   \n",
       "9                     0                    0                    0   \n",
       "10                    0                    0                    0   \n",
       "11                    0                    0                    0   \n",
       "12                    0                    0                    0   \n",
       "13                    0                    0                    0   \n",
       "\n",
       "    TripPurpose_B01ID_10  PSUGOR_B02ID  IndIncome2002_B02ID  HHoldNumChildren  \\\n",
       "0                      0           5.0                  1.0               0.0   \n",
       "1                      0           5.0                  1.0               0.0   \n",
       "2                      0           5.0                  1.0               0.0   \n",
       "3                      0           5.0                  1.0               0.0   \n",
       "4                      0           5.0                  1.0               0.0   \n",
       "5                      0           5.0                  1.0               0.0   \n",
       "6                      0           5.0                  1.0               0.0   \n",
       "7                      0           5.0                  1.0               0.0   \n",
       "8                      0           5.0                  1.0               0.0   \n",
       "9                      0           5.0                  1.0               0.0   \n",
       "10                     0           5.0                  1.0               0.0   \n",
       "11                     0           5.0                  1.0               0.0   \n",
       "12                     0           5.0                  1.0               0.0   \n",
       "13                     0           5.0                  1.0               0.0   \n",
       "\n",
       "    VehMakeModel_B02ID  TWSMonth  TravelYear  \n",
       "0                -10.0       1.0      2017.0  \n",
       "1                -10.0       1.0      2017.0  \n",
       "2                -10.0       1.0      2017.0  \n",
       "3                -10.0       1.0      2017.0  \n",
       "4                -10.0       1.0      2017.0  \n",
       "5                -10.0       1.0      2017.0  \n",
       "6                -10.0       1.0      2017.0  \n",
       "7                -10.0       1.0      2017.0  \n",
       "8                -10.0       1.0      2017.0  \n",
       "9                -10.0       1.0      2017.0  \n",
       "10               -10.0       1.0      2017.0  \n",
       "11               -10.0       1.0      2017.0  \n",
       "12               -10.0       1.0      2017.0  \n",
       "13               -10.0       1.0      2017.0  \n",
       "\n",
       "[14 rows x 47 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = prepare_data_for_LSTM(long_df=ts_df, transform_to_wide=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_travel_weeks(df, transform_to_wide = True):\n",
    "    df = df.copy()\n",
    "    df_chunks = []\n",
    "    full_week_encoding = list(range(1,8))   # Using 0 to indicate start of Sequence, 8 to indicate end of sequence\n",
    "    individual_ids = df[\"IndividualID_x\"].unique()       # All unique individual id's to loop over\n",
    "\n",
    "    for i in individual_ids[:]:\n",
    "        break_flag = False\n",
    "        i_df = df[df[\"IndividualID_x\"] == i]\n",
    "\n",
    "        # Travel days with travel \n",
    "        included_travel_day = i_df[\"TravelWeekDay_B01ID\"].to_list()\n",
    "\n",
    "        # Travel days with no travel\n",
    "        travel_day_no_drive = list(set(full_week_encoding) - set(included_travel_day))\n",
    "\n",
    "\n",
    "        idle_row = {}\n",
    "\n",
    "        # These values will repeat for empty-travel travel days\n",
    "        imputed_travel_df = pd.DataFrame({\n",
    "            \"TravelWeekDay_B01ID\": travel_day_no_drive,\n",
    "            \"IndividualID_x\": [i]*len(travel_day_no_drive),\n",
    "            \"JourSeq\": [1]*len(travel_day_no_drive)\n",
    "        })\n",
    "\n",
    "        # Looping through all the columns in the original df\n",
    "        for col in i_df.columns:\n",
    "\n",
    "            # For days with no travel all outcomes vars will take 0\n",
    "            if col in outcome_vars:\n",
    "                imputed_travel_df[col] = [0]*len(travel_day_no_drive)\n",
    "            \n",
    "            # Individual vars will repeat\n",
    "            if col in individual_vars:\n",
    "\n",
    "                # Repeating individual vars (or temporal vars) usually signify an error\n",
    "                if len(i_df[col].unique()) != 1:\n",
    "                    print(f\"{col} is erroneous for {i}\")\n",
    "                    print(f\"Unique vals: {i_df[col].unique()}\")\n",
    "                    break_flag = True\n",
    "                    break\n",
    "                else:\n",
    "                    imputed_travel_df[col] = i_df[col].unique()[0]\n",
    "                    idle_row[col] = i_df[col].unique()[0]\n",
    "\n",
    "            if col != \"TravelWeekDay_B01ID\" and col in temporal_vars:\n",
    "                if len(i_df[col].unique()) != 1:\n",
    "                    print(f\"{col} is erroneous for {i}\")\n",
    "                    print(f\"Unique vals: {i_df[col].unique()}\")\n",
    "                    break_flag = True\n",
    "                    break\n",
    "                else:\n",
    "                    imputed_travel_df[col] = i_df[col].unique()[0]\n",
    "                    idle_row[col] = i_df[col].unique()[0]\n",
    "\n",
    "        if break_flag:\n",
    "            print(\"Continuing to next individual\")\n",
    "            continue\n",
    "\n",
    "        # Concatenating df to include empty travel days\n",
    "        full_df = pd.concat([i_df, imputed_travel_df])\n",
    "\n",
    "        # Transforming to wide format\n",
    "        if transform_to_wide:\n",
    "            full_df = transform_to_wide_func(full_df, 10)\n",
    "\n",
    "            # Add Individual ID columns\n",
    "            for col in i_df.columns:\n",
    "                if col in individual_vars:\n",
    "                    full_df[col] = i_df[col].unique()[0]\n",
    "                if col in temporal_vars:\n",
    "                    full_df[col] = i_df[col].unique()[0]\n",
    "\n",
    "            full_df[\"IndividualID_x\"] = [i]*len(full_df)\n",
    "                \n",
    "            #display(full_df)\n",
    "\n",
    "        df_chunks.append(full_df)\n",
    "\n",
    "        #display(imputed_travel_df)\n",
    "        #print(\"\")\n",
    "        #display(full_df)\n",
    "\n",
    "    df_to_return = pd.concat(df_chunks)\n",
    "\n",
    "    if not transform_to_wide:\n",
    "        df_to_return = df_to_return.sort_values([\"IndividualID_x\", \"TravelYear\", \"TWSMonth\", \"TravelWeekDay_B01ID\", \"JourSeq\", \"TripStart\", \"TripEnd\"] )[[\"IndividualID_x\", \"JourSeq\"] + outcome_vars + temporal_vars]\n",
    "\n",
    "\n",
    "        df_to_return.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        df_to_return.fillna(0, inplace=True)\n",
    "\n",
    "        return df_to_return\n",
    "    \n",
    "    else:\n",
    "        df_to_return.fillna(0, inplace=True)\n",
    "        return df_to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TravelYear is erroneous for 2017014397.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017014398.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017014552.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017014714.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017014715.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017014773.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017014964.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017014965.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015043.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015044.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015045.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015046.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015097.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015137.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015147.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015165.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015191.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015192.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015193.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015196.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015249.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015258.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015305.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015342.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015362.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015387.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015388.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015390.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015397.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015398.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015477.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015479.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015496.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015562.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015569.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015579.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015581.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015582.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015588.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015590.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015602.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015624.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015625.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015642.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015644.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015659.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015667.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015668.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015671.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015701.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015704.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015726.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015756.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015765.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015770.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015800.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015811.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015860.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015862.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015867.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015868.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015915.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n",
      "TravelYear is erroneous for 2017015980.0\n",
      "Unique vals: [2018. 2017.]\n",
      "Continuing to next individual\n"
     ]
    }
   ],
   "source": [
    "df = impute_missing_travel_weeks(ts_df)\n",
    "\n",
    "# When we are moving from year to year. Probably not a huge issue but might fix later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/home/trapfishscott/Cambridge24.25/D200_ML_econ/ProblemSets/Project/data/play_wide.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_trial_2 = pivot_trial.pivot(index=\"TravelWeekDay_B01ID\",\n",
    "                  columns = \"JourSeq\",\n",
    "                  values = [\"TripStart\", \"TripEnd\", \"TripDisExSW\",\t\"TripPurpose_B01ID\"]).reset_index()\n",
    "\n",
    "pivot_trial_2[\"Hello\"] = [0]*len(pivot_trial_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>TravelWeekDay_B01ID</th>\n",
       "      <th colspan=\"2\" halign=\"left\">TripStart</th>\n",
       "      <th colspan=\"2\" halign=\"left\">TripEnd</th>\n",
       "      <th colspan=\"2\" halign=\"left\">TripDisExSW</th>\n",
       "      <th colspan=\"2\" halign=\"left\">TripPurpose_B01ID</th>\n",
       "      <th>Hello</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JourSeq</th>\n",
       "      <th></th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>690.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>995.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TravelWeekDay_B01ID TripStart        TripEnd        TripDisExSW       \\\n",
       "JourSeq                           1.0    2.0     1.0    2.0         1.0  2.0   \n",
       "0                       0.0       0.0    0.0     0.0    0.0         0.0  0.0   \n",
       "1                       1.0     600.0  690.0   620.0  710.0         4.0  4.0   \n",
       "2                       2.0       0.0    0.0     0.0    0.0         0.0  0.0   \n",
       "3                       3.0       0.0    0.0     0.0    0.0         0.0  0.0   \n",
       "4                       4.0       0.0    0.0     0.0    0.0         0.0  0.0   \n",
       "5                       5.0     540.0  960.0   580.0  995.0         6.0  6.0   \n",
       "6                       6.0       0.0    0.0     0.0    0.0         0.0  0.0   \n",
       "7                       7.0       0.0    0.0     0.0    0.0         0.0  0.0   \n",
       "8                       8.0       0.0    0.0     0.0    0.0         0.0  0.0   \n",
       "\n",
       "        TripPurpose_B01ID       Hello  \n",
       "JourSeq               1.0   2.0        \n",
       "0                     0.0   0.0     0  \n",
       "1                     6.0   6.0     0  \n",
       "2                     0.0   0.0     0  \n",
       "3                     0.0   0.0     0  \n",
       "4                     0.0   0.0     0  \n",
       "5                    13.0  13.0     0  \n",
       "6                     0.0   0.0     0  \n",
       "7                     0.0   0.0     0  \n",
       "8                     0.0   0.0     0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_trial_2.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to LSTM\n",
    "\n",
    "def convert_to_tensor(df, seq_length, cols_to_drop, debug=True):\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    df = df.drop(columns=cols_to_drop, axis=1, errors=\"ignore\")\n",
    "\n",
    "    df_array = df.to_numpy()\n",
    "\n",
    "    # Drop observations to make it fit sequence length\n",
    "\n",
    "    rows_to_drop = df_array.shape[0] % seq_length\n",
    "\n",
    "    if rows_to_drop > 0:\n",
    "        df_array = df_array[:-rows_to_drop,:]\n",
    "\n",
    "    print(df_array.shape)\n",
    "\n",
    "    n = int(df_array.shape[0]/seq_length)\n",
    "    input_features = int(df_array.shape[1])\n",
    "\n",
    "    df_array = df_array.reshape((n, seq_length, input_features))\n",
    "\n",
    "    df_array = df_array.transpose(1,0,2)\n",
    "\n",
    "    print(f\"Reshaped (seq_length, n_batches, input_features): {df_array.shape}\")\n",
    "\n",
    "    # Ensuring the array transformation matches the df\n",
    "\n",
    "    if debug is True:\n",
    "\n",
    "        test_value = random.randint(0,df_array.shape[0])\n",
    "\n",
    "        assert np.array_equal(\n",
    "            df_array[:,test_value,:],\n",
    "            df.iloc[test_value*seq_length:test_value*seq_length+seq_length, :].to_numpy()\n",
    "        ), \"Mismatch between reshaped array and original df\"\n",
    "\n",
    "    tensor_data = torch.tensor(df_array, dtype=torch.float32)\n",
    "\n",
    "    return tensor_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126602, 8)\n",
      "Reshaped (seq_length, n_batches, input_features): (14, 9043, 8)\n"
     ]
    }
   ],
   "source": [
    "travel_tensor = convert_to_tensor(df=df, seq_length=14, cols_to_drop=[\"JourSeq\", \"NumTrips\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TripStart', 'TripEnd', 'TripDisExSW', 'TripPurpose_B01ID']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining parameters\n",
    "INPUT_SIZE = travel_tensor.shape[2]\n",
    "HIDDEN_SIZE = 3\n",
    "NUM_LAYERS = 1\n",
    "OUTPUT_SIZE = len(outcome_vars)\n",
    "\n",
    "outcome_vars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNmodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Define RNN layer\n",
    "\n",
    "        self.rnn = nn.RNN(INPUT_SIZE, HIDDEN_SIZE)\n",
    "\n",
    "        # Output layer\n",
    "\n",
    "        self.output = nn.Linear(HIDDEN_SIZE, OUTPUT_SIZE)\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        out, hh = self.rnn(X)\n",
    "\n",
    "        print(f\"out shape: {out.shape}\")\n",
    "        print(f\"hh shape: {hh.shape}\")\n",
    "\n",
    "        y_hat_vector = self.output(hh)\n",
    "\n",
    "        print(f\"y_hat shape: {y_hat_vector.shape}\")\n",
    "\n",
    "        print(y_hat_vector)\n",
    "\n",
    "        y_hat = {}\n",
    "\n",
    "        for index in range(y_hat_vector.shape[2]):\n",
    "            y_hat[index+1] = y_hat_vector[:,:,index].detach()\n",
    "\n",
    "        return y_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 shape: torch.Size([14, 1, 8])\n",
      "out shape: torch.Size([14, 1, 3])\n",
      "hh shape: torch.Size([1, 1, 3])\n",
      "y_hat shape: torch.Size([1, 1, 4])\n",
      "tensor([[[ 0.5506, -0.3124,  0.2871, -0.1610]]], grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: tensor([[0.5506]]),\n",
       " 2: tensor([[-0.3124]]),\n",
       " 3: tensor([[0.2871]]),\n",
       " 4: tensor([[-0.1610]])}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking one test draw\n",
    "\n",
    "rnn_model = RNNmodel()\n",
    "\n",
    "X1 = travel_tensor[:,0,:].unsqueeze(1)\n",
    "print(f\"X1 shape: {X1.shape}\")\n",
    "\n",
    "y_hat = rnn_model.forward(X1)\n",
    "\n",
    "y_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_cat = nn.CrossEntropyLoss()  #(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LSTM for single batch size\n",
    "\n",
    "# Looping over batch dimension\n",
    "\n",
    "for batch in range(travel_tensor.shape[1]):\n",
    "    print(travel_tensor[:,batch,:].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLEconPS2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
